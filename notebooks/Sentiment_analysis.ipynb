{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149a7850-08c0-4d32-af84-1ee77b58b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Sentiment and Technical Analysis Tools\n",
    "from textblob import TextBlob\n",
    "#import talib\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7aa5cc-5935-45ad-b32a-6b8c0bd23a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date      Open      High       Low     Close  Adj Close     Volume  \\\n",
      "0  1980-12-12  0.128348  0.128906  0.128348  0.128348   0.098943  469033600   \n",
      "1  1980-12-15  0.122210  0.122210  0.121652  0.121652   0.093781  175884800   \n",
      "2  1980-12-16  0.113281  0.113281  0.112723  0.112723   0.086898  105728000   \n",
      "3  1980-12-17  0.115513  0.116071  0.115513  0.115513   0.089049   86441600   \n",
      "4  1980-12-18  0.118862  0.119420  0.118862  0.118862   0.091630   73449600   \n",
      "\n",
      "   Dividends  Stock Splits  \n",
      "0        0.0           0.0  \n",
      "1        0.0           0.0  \n",
      "2        0.0           0.0  \n",
      "3        0.0           0.0  \n",
      "4        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paths\n",
    "zip_path = 'C:/Users/dell/Downloads/yfinance_data.zip'\n",
    "extract_to = 'C:/Users/dell/Downloads/yfinance_data'  # Folder to extract to\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "# Extract the ZIP\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "# Now read the CSV\n",
    "csv_path = f'{extract_to}/yfinance_data/AAPL_historical_data.csv'\n",
    "stock_df = pd.read_csv(csv_path)\n",
    "\n",
    "print(stock_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b6c554-d3de-44b2-853f-e05a2ff4c356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                        date stock  \n",
      "0  2020-06-05 10:30:54-04:00     A  \n",
      "1  2020-06-03 10:45:20-04:00     A  \n",
      "2  2020-05-26 04:30:07-04:00     A  \n",
      "3  2020-05-22 12:45:06-04:00     A  \n",
      "4  2020-05-22 11:38:59-04:00     A  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paths\n",
    "zip_path = 'C:/Users/dell/Downloads/raw_analyst_ratings.csv.zip'\n",
    "extract_to = 'C:/Users/dell/Downloads/extracted_data'  # Folder to extract to\n",
    "\n",
    "# Extract the ZIP\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "# Now read the CSV\n",
    "csv_path = f'{extract_to}/raw_analyst_ratings.csv'  # Adjust if filename is different\n",
    "ratings_df = pd.read_csv(csv_path)\n",
    "\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ef9dc-5b85-42d0-bc25-480434d36225",
   "metadata": {},
   "source": [
    "# 3. Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4622946-8a3a-42ce-bdf2-606708c99b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date      Open      High       Low     Close  Adj Close     Volume  \\\n",
      "0  1980-12-12  0.128348  0.128906  0.128348  0.128348   0.098943  469033600   \n",
      "1  1980-12-15  0.122210  0.122210  0.121652  0.121652   0.093781  175884800   \n",
      "2  1980-12-16  0.113281  0.113281  0.112723  0.112723   0.086898  105728000   \n",
      "3  1980-12-17  0.115513  0.116071  0.115513  0.115513   0.089049   86441600   \n",
      "4  1980-12-18  0.118862  0.119420  0.118862  0.118862   0.091630   73449600   \n",
      "\n",
      "   Dividends  Stock Splits  \n",
      "0        0.0           0.0  \n",
      "1        0.0           0.0  \n",
      "2        0.0           0.0  \n",
      "3        0.0           0.0  \n",
      "4        0.0           0.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10998 entries, 0 to 10997\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date          10998 non-null  object \n",
      " 1   Open          10998 non-null  float64\n",
      " 2   High          10998 non-null  float64\n",
      " 3   Low           10998 non-null  float64\n",
      " 4   Close         10998 non-null  float64\n",
      " 5   Adj Close     10998 non-null  float64\n",
      " 6   Volume        10998 non-null  int64  \n",
      " 7   Dividends     10998 non-null  float64\n",
      " 8   Stock Splits  10998 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 773.4+ KB\n",
      "None\n",
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                        date stock  \n",
      "0  2020-06-05 10:30:54-04:00     A  \n",
      "1  2020-06-03 10:45:20-04:00     A  \n",
      "2  2020-05-26 04:30:07-04:00     A  \n",
      "3  2020-05-22 12:45:06-04:00     A  \n",
      "4  2020-05-22 11:38:59-04:00     A  \n",
      "publisher\n",
      "Paul Quintaro        228373\n",
      "Lisa Levin           186979\n",
      "Benzinga Newsdesk    150484\n",
      "Charles Gross         96732\n",
      "Monica Gerson         82380\n",
      "                      ...  \n",
      "Matthew Ely               1\n",
      "Frank Ochoa               1\n",
      "Jeremie Capron            1\n",
      "Marvin Dumont             1\n",
      "Igor Gonta                1\n",
      "Name: count, Length: 1034, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Stock Data Overview\n",
    "print(stock_df.head())\n",
    "print(stock_df.info())\n",
    "\n",
    "# Ratings Dataset Overview\n",
    "print(ratings_df.head())\n",
    "print(ratings_df['publisher'].value_counts())\n",
    "ratings_df['headline_length'] = ratings_df['headline'].apply(len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c990b-293f-46b9-80e4-3155d6d9fe6d",
   "metadata": {},
   "source": [
    "# 4. Sentiment Analysis (Task 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44581256-6d19-4104-8942-8c5757a50c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_9008\\50233189.py:7: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  ratings_df['date'] = pd.to_datetime(ratings_df['date'], format='mixed').dt.date\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m ratings_df[\u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m] = ratings_df[\u001b[33m'\u001b[39m\u001b[33mheadline\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: TextBlob(\u001b[38;5;28mstr\u001b[39m(x)).sentiment.polarity)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Fix the datetime parsing - use one of these options:\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# OPTION 1: Let pandas automatically infer the format (recommended)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m ratings_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmixed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdt\u001b[49m.date\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# OPTION 2: Explicitly specify ISO8601 format\u001b[39;00m\n\u001b[32m     10\u001b[39m ratings_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(ratings_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mISO8601\u001b[39m\u001b[33m'\u001b[39m).dt.date\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[39m, in \u001b[36mNDFrame.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   6293\u001b[39m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._internal_names_set\n\u001b[32m   6294\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._metadata\n\u001b[32m   6295\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessors\n\u001b[32m   6296\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6297\u001b[39m ):\n\u001b[32m   6298\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[32m-> \u001b[39m\u001b[32m6299\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[39m, in \u001b[36mCachedAccessor.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessor\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m accessor_obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;28mobject\u001b[39m.\u001b[34m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m._name, accessor_obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:643\u001b[39m, in \u001b[36mCombinedDatetimelikeProperties.__new__\u001b[39m\u001b[34m(cls, data)\u001b[39m\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data.dtype, PeriodDtype):\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute sentiment (this part is working)\n",
    "ratings_df['sentiment'] = ratings_df['headline'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "\n",
    "# Fix the datetime parsing - use one of these options:\n",
    "\n",
    "# OPTION 1: Let pandas automatically infer the format (recommended)\n",
    "ratings_df['date'] = pd.to_datetime(ratings_df['date'], format='mixed').dt.date\n",
    "\n",
    "# OPTION 2: Explicitly specify ISO8601 format\n",
    "ratings_df['date'] = pd.to_datetime(ratings_df['date'], format='ISO8601').dt.date\n",
    "\n",
    "# OPTION 3: If you know the exact format (e.g., \"2020-05-22 00:00:00\")\n",
    "ratings_df['date'] = pd.to_datetime(ratings_df['date'], format='%Y-%m-%d %H:%M:%S').dt.date\n",
    "\n",
    "# Then proceed with your analysis\n",
    "daily_sentiment = ratings_df.groupby('date')['sentiment'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996da4e-3c9d-4914-b1e7-32bbe1dd6049",
   "metadata": {},
   "source": [
    "# 5. Time Series Technical Analysis (Task 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dce95b-7f41-44c5-8a97-d9d079bf487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert stock date and compute daily return\n",
    "stock_df['Date'] = pd.to_datetime(stock_df['Date'])\n",
    "stock_df['daily_return'] = stock_df['Close'].pct_change()\n",
    "\n",
    "# Technical Indicators\n",
    "stock_df['SMA_10'] = talib.SMA(stock_df['Close'], timeperiod=10)\n",
    "stock_df['RSI'] = talib.RSI(stock_df['Close'], timeperiod=14)\n",
    "stock_df['MACD'], _, _ = talib.MACD(stock_df['Close'])\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(stock_df['Date'], stock_df['Close'], label='Close Price')\n",
    "plt.plot(stock_df['Date'], stock_df['SMA_10'], label='SMA_10')\n",
    "plt.legend()\n",
    "plt.title('Stock Price with SMA')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2364c-221d-4bb5-9aee-e92b119a758b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (Correct)",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
